{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a GPT model from scratch to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "        \"vocab_size\": 50257, # Vocabulary size\n",
    "        \"context_length\": 1024, # Context length\n",
    "        \"emb_dim\": 768, # Embedding dimension\n",
    "        \"n_heads\": 12, # Number of attention heads\n",
    "        \"n_layers\": 12, # Number of layers\n",
    "        \"drop_rate\": 0.1, # Dropout rate\n",
    "        \"qkv_bias\": False # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will code a GPT model following:\n",
    "\n",
    "- 1) GPT backbone\n",
    "- 2) Layer Normalization\n",
    "- 3) GELU activation\n",
    "- 4) Feed forward network\n",
    "- 5) Shortcut connections\n",
    "- 6) Transformer block\n",
    "- 7) Final GPT architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) GPT backbone model architecture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential( # placeholder for TransformerBlock\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"]) # placeholder for LayerNorm\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward (self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "    \n",
    "class DummyTransformerBlock(nn.Module): # placeholder to be replaced by a real transformer block\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "class DummyLayerNorm(nn.Module): # to be replaced by layernorm interface\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# initialize a 124M param model instance and feed it with the batch\n",
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\" , logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5 # prevent div by 0 during normalization\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) # use biased variance, so div by n, not n-1\n",
    "        # this is practically negligible for large n, but matches the original GPT-2 implementation\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.5528,  1.0693, -0.0223,  0.2656, -1.8654],\n",
      "        [ 0.9087, -1.3767, -0.9564,  1.1304,  0.2940]], grad_fn=<AddBackward0>)\n",
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_ln)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer norm normalizes each input independently of the batch size, it offers more flexibility and stability where resources are limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) GELU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of the GELU activation function\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "        torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "        (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(7, 3))\n",
    "\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing feed forward layer with GELU activation\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], cfg[\"emb_dim\"] * 4),\n",
    "            GELU(),\n",
    "            nn.Linear(cfg[\"emb_dim\"] * 4, cfg[\"emb_dim\"])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n",
      "tensor([[[ 0.1238,  0.0457,  0.0939,  ...,  0.1107,  0.0167, -0.1992],\n",
      "         [ 0.1574, -0.0282,  0.0049,  ...,  0.0026,  0.1120, -0.1075],\n",
      "         [ 0.1184, -0.0052,  0.0839,  ...,  0.1662,  0.0112, -0.1685]],\n",
      "\n",
      "        [[ 0.1302,  0.0630,  0.1050,  ...,  0.1439,  0.0562, -0.1128],\n",
      "         [ 0.1249, -0.0073,  0.1022,  ...,  0.0417,  0.0381, -0.0828],\n",
      "         [ 0.0494,  0.0654,  0.0347,  ...,  0.0701,  0.0793, -0.1810]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) # 2, 3 e.g.\n",
    "out = ffn(x)\n",
    "print(out.shape)\n",
    "print(out)\n",
    "\n",
    "# inputs are projected to 4 times the embedding dimension, passed through the GELU activation function, \n",
    "# and then projected back to the original embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: torch.Size([2, 3, 2, 2])\n",
      "Batch 0, Channel 0:\n",
      "tensor([[8, 2],\n",
      "        [5, 2]])\n",
      "Batch 0, Channel 1:\n",
      "tensor([[9, 3],\n",
      "        [8, 4]])\n",
      "Batch 0, Channel 2:\n",
      "tensor([[5, 0],\n",
      "        [6, 5]])\n",
      "Batch 1, Channel 0:\n",
      "tensor([[7, 9],\n",
      "        [7, 2]])\n",
      "Batch 1, Channel 1:\n",
      "tensor([[6, 2],\n",
      "        [2, 2]])\n",
      "Batch 1, Channel 2:\n",
      "tensor([[8, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# cool way to visualize high-dimensional tensors\n",
    "tensor_4d = torch.randint(0, 10, (2, 3, 2, 2))  # Random 4D tensor\n",
    "\n",
    "print(\"Tensor shape:\", tensor_4d.shape)\n",
    "\n",
    "# Iterate over the first two dimensions\n",
    "for b in range(tensor_4d.shape[0]):  # Batch\n",
    "    for c in range(tensor_4d.shape[1]):  # Channel\n",
    "        print(f\"Batch {b}, Channel {c}:\")\n",
    "        print(tensor_4d[b, c])  # Each is a 2x2 matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Shortcut connections (residual connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deep networks, especially those with many layers (like GPT or ResNets), vanishing gradients can prevent the network from learning effective features because the early layers receive negligible updates during training. Residual connections mitigate this by ensuring that gradients have a clear, strong path to flow back through, thereby allowing more effective training of deep architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([ # five layers with GELU activation\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]),\n",
    "                    GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]),\n",
    "                    GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]),\n",
    "                    GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]),\n",
    "                    GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]),\n",
    "                    GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x) # compute output of each layer\n",
    "            if self.use_shortcut and x.shape == layer_output.shape: # check if shortcut can be used\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's implement a function that computes the gradients in the model backward pass\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    output = model(x) # forward pass\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target) # compute loss based on how close the output is to the target\n",
    "\n",
    "    loss.backward() # backward pass to compute gradients\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152039906941354\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "source": [
    "# gradient becoming smaller as we progress to the earlier layers (vanishing gradient problem)\n",
    "# let's now compare it with the model that uses the shortcut\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient stabilized as we progress from earlier layers (though layer 4 has a slightly higher gradient)\n",
    "\n",
    "- The particularly high gradient in layer 4 is likely due to its proximity to the loss and possibly the cumulative effect of the residual connections. This isnâ€™t necessarily a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import previous MultiHeadAttention class from previous chapters:\n",
    "\n",
    "# now, with weight-splits combining both the wrapper and causal attention\n",
    "# multi-head attention class should split the input into multiple heads\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out,\n",
    "                context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # reduces the projection dim to match desired output dim\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out) # uses linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) # split matrix adding num_heads dim\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim) # Then we unroll the last dim: d_out -> num_heads, head_dim\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim) # output (b, num_tokens, num_heads, head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2) # transpose from b, num_tokens, num_heads, head_dim -->\n",
    "        queries = queries.transpose(1, 2) # b, num_heads, num_tokens, head_dim\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) # transpose back to b, num_tokens, num_heads, head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out) # reshape to b, num_tokens, d_out\n",
    "        context_vec = self.out_proj(context_vec) # adds optional linear projection\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a class for the transformer block that uses the multi-head attention class\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut= nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        shortcut = x # shortcut connection for attn block\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # add the original input to the output of the attn block\n",
    "\n",
    "        shortcut = x # shortcut connection for ff block\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # add the original input to the output of the ff layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We defined the `TransformerBlock` class including `MultiHeadAttention`and a feed forward network, both using the `cgf` dict from gpt config params.\n",
    "\n",
    "- Layer normalization (LayerNorm) is applied before each of these two components,\n",
    "and dropout is applied after them to regularize the model and prevent overfitting. This\n",
    "is also known as Pre-LayerNorm. Older architectures, such as the original transformer\n",
    "model, applied layer normalization after the self-attention and feed forward networks\n",
    "instead, known as Post-LayerNorm, which often leads to worse training dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "tensor([[[-0.0055,  0.0972, -0.1122,  ...,  1.2889,  0.2623,  0.6685],\n",
      "         [ 0.0023, -0.2369,  0.1720,  ...,  0.5952,  0.2497,  0.7447],\n",
      "         [ 0.4673,  0.4472,  0.1791,  ...,  1.2525,  0.3045,  0.7750],\n",
      "         [ 0.0662,  0.7224,  0.9206,  ...,  0.4790,  0.7428,  0.7015]],\n",
      "\n",
      "        [[ 0.3622,  1.2144,  0.5221,  ...,  0.1854,  0.0111, -0.5034],\n",
      "         [-0.0225,  0.7789,  0.2770,  ...,  0.1734,  0.5419,  0.1143],\n",
      "         [ 0.7425,  0.4013,  0.3211,  ...,  0.3268,  0.7523, -0.1642],\n",
      "         [ 0.5745,  0.6241,  0.4410,  ...,  1.1963,  1.2650,  0.2243]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4 , 768) # batch, num_tokens, emb_dim\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"\\nOutput shape:\", output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The preservation of shape throughout the transformer block architecture is not\n",
    "incidental but a crucial aspect of its design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Final GPT architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will redo a bit the dummy classes created in the beginning. Note that the transformer block is repeated n_layers times (12) in our version (GPT-2), while 48 times in the largest version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's reuse the DummyGPTModel class \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential( # placeholder for TransformerBlock\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"]) # placeholder for LayerNorm\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward (self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "    \n",
    "class DummyTransformerBlock(nn.Module): # placeholder to be replaced by a real transformer block\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "class DummyLayerNorm(nn.Module): # to be replaced by layernorm interface\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device) # select device to train\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6109, 3626, 6100,  345],\n",
       "        [6109, 1110, 6622,  257]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([2, 4])\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch shape:\", batch.shape)\n",
    "print(\"Output shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 163009536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference on 163M params opposed to 124M, relies on the \"weight tying concept\", which is a technique that allows the model to share the weights between the token embeddings and the output layer. The weight tying technique is used in the GPT-2 model to reduce the number of parameters and improve the training efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And removing the params from the output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = (\n",
    "    total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    ")\n",
    "\n",
    "print(f\"Number of trainable parameters \"\n",
    "f\"considering weight tying: {total_params_gpt2:,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now close to the 124M specified. Despite weight tying improving efficiency, author usually prefers to keep token embeddings and output layer separated. If we were to count the params in ffn module and those contained in the multi-head attention module, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First Transformer Block ===\n",
      "Multi-head Attention parameters: 2360064\n",
      "Feed Forward parameters: 4722432\n",
      "\n",
      "=== All Transformer Blocks ===\n",
      "Total Multi-head Attention parameters: 28320768\n",
      "Total attn params == 1 block * n layers is:  True\n",
      "Total Feed Forward parameters: 56669184\n",
      "Total ffn params == 1 ffn * n layers is:  True\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(module):\n",
    "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "\n",
    "# Count parameters for the first transformer block\n",
    "first_block = model.trf_blocks[0]\n",
    "attn_params_block0 = count_parameters(first_block.att)\n",
    "ffn_params_block0 = count_parameters(first_block.ff)\n",
    "\n",
    "print(\"=== First Transformer Block ===\")\n",
    "print(\"Multi-head Attention parameters:\", attn_params_block0)\n",
    "print(\"Feed Forward parameters:\", ffn_params_block0)\n",
    "\n",
    "# Optionally, compute total parameters across all transformer blocks\n",
    "total_attn_params = sum(count_parameters(block.att) for block in model.trf_blocks)\n",
    "total_ffn_params  = sum(count_parameters(block.ff) for block in model.trf_blocks)\n",
    "\n",
    "print(\"\\n=== All Transformer Blocks ===\")\n",
    "print(\"Total Multi-head Attention parameters:\", total_attn_params)\n",
    "print(\"Total attn params == 1 block * n layers is: \", total_attn_params == attn_params_block0 * GPT_CONFIG_124M[\"n_layers\"])\n",
    "print(\"Total Feed Forward parameters:\", total_ffn_params)\n",
    "print(\"Total ffn params == 1 ffn * n layers is: \", total_ffn_params == ffn_params_block0 * GPT_CONFIG_124M[\"n_layers\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652038144"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_size_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model size: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "# computing memory size needed for the model\n",
    "\n",
    "total_size_bytes = total_params * 4 # 4 bytes per param, assuming all parameters are float32\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total model size: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPT-2 Medium ===\n",
      "Total parameters: 406,212,608\n",
      "Total model size: 1549.58 MB\n",
      "========================================\n",
      "=== GPT-2 Large ===\n",
      "Total parameters: 838,220,800\n",
      "Total model size: 3197.56 MB\n",
      "========================================\n",
      "=== GPT-2 XL ===\n",
      "Total parameters: 1,637,792,000\n",
      "Total model size: 6247.68 MB\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Testing different model sizes from GPT-2 series\n",
    "\n",
    "def print_model_info(config, model_name):\n",
    "    torch.manual_seed(123)  # for reproducibility\n",
    "    model = GPTModel(config)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    total_size_bytes = total_params * 4  # 4 bytes per parameter (float32)\n",
    "    total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "    \n",
    "    print(f\"=== {model_name} ===\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Total model size: {total_size_mb:.2f} MB\")\n",
    "    print(\"=\"*40)\n",
    "    return model\n",
    "\n",
    "# GPT-2 Medium: 1,024-dimensional embeddings, 24 transformer blocks, 16 multi-head attention heads\n",
    "GPT_CONFIG_medium = {\n",
    "    \"vocab_size\": 50257,       # Vocabulary size (e.g., from GPT-2)\n",
    "    \"context_length\": 1024,    # Maximum sequence length\n",
    "    \"emb_dim\": 1024,           # Embedding dimension\n",
    "    \"n_heads\": 16,             # Number of attention heads\n",
    "    \"n_layers\": 24,            # Number of transformer blocks\n",
    "    \"drop_rate\": 0.1,          # Dropout rate\n",
    "    \"qkv_bias\": False          # Whether to use bias in query/key/value projections\n",
    "}\n",
    "\n",
    "# GPT-2 Large: 1,280-dimensional embeddings, 36 transformer blocks, 20 multi-head attention heads\n",
    "GPT_CONFIG_large = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 1280,           # Embedding dimension\n",
    "    \"n_heads\": 20,             # Attention heads\n",
    "    \"n_layers\": 36,            # Transformer blocks\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "# GPT-2 XL: 1,600-dimensional embeddings, 48 transformer blocks, 25 multi-head attention heads\n",
    "GPT_CONFIG_XL = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 1600,           # Embedding dimension\n",
    "    \"n_heads\": 25,             # Attention heads\n",
    "    \"n_layers\": 48,            # Transformer blocks\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "# Instantiate and print information for each model\n",
    "model_medium = print_model_info(GPT_CONFIG_medium, \"GPT-2 Medium\")\n",
    "model_large  = print_model_info(GPT_CONFIG_large,  \"GPT-2 Large\")\n",
    "model_XL     = print_model_info(GPT_CONFIG_XL,     \"GPT-2 XL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Generating text with the GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size): # idx is a (batch, n_tokens) tensor\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:] # crops current context if it exceeds context size\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # model generates logits for the next token\n",
    "\n",
    "        logits = logits[:, -1, :] # selects the last token in the sequence: (batch, n_tokens, vocab_size) \n",
    "                                    #-> (batch, vocab_size)\n",
    "        probas = torch.softmax(logits, dim=-1) # converts logits to probabilities\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # selects the most likely token (batch, 1)\n",
    "        idx = torch.cat([idx, idx_next], dim=-1) # appends the new token to the sequence, where idx has shape (batch, n_tokens+1)\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The softmax function is monotonic, meaning it\n",
    "preserves the order of its inputs when transformed into outputs. So, in practice, the\n",
    "softmax step is redundant since the position with the highest score in the softmax out-\n",
    "put tensor is the same position in the logit tensor. In other words, we could apply the\n",
    "torch.argmax function to the logits tensor directly and get identical results. However,\n",
    "I provide the code for the conversion to illustrate the full process of transforming log-\n",
    "its to probabilities, which can add additional intuition so that the model generates the\n",
    "most likely next token, which is known as \"greedy decoding\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() # disable dropout since we are not training the model\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Garbage as expected - some bench press is needed :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lit-llm-usCjbgK0-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
