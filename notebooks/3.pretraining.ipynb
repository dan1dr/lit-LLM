{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining\n",
    "\n",
    "For this stage, we would implement:\n",
    "\n",
    "1. Training loop\n",
    "2. Model eval\n",
    "3. Load pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, let's recap on text generation, text evaluation, and training val & losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5 # prevent div by 0 during normalization\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) # use biased variance, so div by n, not n-1\n",
    "        # this is practically negligible for large n, but matches the original GPT-2 implementation\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out,\n",
    "                context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # reduces the projection dim to match desired output dim\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out) # uses linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) # split matrix adding num_heads dim\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim) # Then we unroll the last dim: d_out -> num_heads, head_dim\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim) # output (b, num_tokens, num_heads, head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2) # transpose from b, num_tokens, num_heads, head_dim -->\n",
    "        queries = queries.transpose(1, 2) # b, num_heads, num_tokens, head_dim\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) # transpose back to b, num_tokens, num_heads, head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out) # reshape to b, num_tokens, d_out\n",
    "        context_vec = self.out_proj(context_vec) # adds optional linear projection\n",
    "        return context_vec\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "        torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "        (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], cfg[\"emb_dim\"] * 4),\n",
    "            GELU(),\n",
    "            nn.Linear(cfg[\"emb_dim\"] * 4, cfg[\"emb_dim\"])\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut= nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        shortcut = x # shortcut connection for attn block\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # add the original input to the output of the attn block\n",
    "\n",
    "        shortcut = x # shortcut connection for ff block\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut # add the original input to the output of the ff layer\n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device) # select device to train\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 256, # shorten from 1024 to 256 for faster training\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "\"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemeting the text generation\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size): # idx is a (batch, n_tokens) tensor\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:] # crops current context if it exceeds context size\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # model generates logits for the next token\n",
    "\n",
    "        logits = logits[:, -1, :] # selects the last token in the sequence: (batch, n_tokens, vocab_size) \n",
    "                                    #-> (batch, vocab_size)\n",
    "        probas = torch.softmax(logits, dim=-1) # converts logits to probabilities\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # selects the most likely token (batch, 1)\n",
    "        idx = torch.cat([idx, idx_next], dim=-1) # appends the new token to the sequence, where idx has shape (batch, n_tokens+1)\n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dim\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dim\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens = 10,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "\n",
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "# calculate text generation loss. let's see first an example on how to calculate the loss for a single batch\n",
    "\n",
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "                       [40, 1107, 588]]) # \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345], # [\"effort moves you\",\n",
    "                        [1107, 588, 11311]]) # \"really like\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "    probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"\\nToken IDs:\\n\", token_ids)\n",
    "\n",
    "print(f\"\\nTargets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# printing the probabilities of the target tokens\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log probabilities:\n",
      " tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "\n",
      "Avg log probability: tensor(-10.7940)\n",
      "\n",
      "Avg neg log prob: tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\"\\nLog probabilities:\\n\", log_probas)\n",
    "\n",
    "#avg_log_proba = log_probas.mean()\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(\"\\nAvg log probability:\", avg_log_probas)\n",
    "\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(\"\\nAvg neg log prob:\", neg_avg_log_probas) # also known as cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross entropy loss** At its core, the cross entropy loss is a popular measure in machine learning and deep\n",
    "learning that measures the difference between two probability distributions -- typically, the true distribution of labels (here, tokens in a dataset) and the predicted distribution from a model (for instance, the token probabilities generated by an LLM). \n",
    "\n",
    "cross entropy ≈= negative avg log probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n",
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)\n",
    "\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross entropy loss: tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# cross entropy will calculate the log softmax and then the negative log likelihood\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\"\\nCross entropy loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Perplexity** is a measure often used alongside cross entropy loss to evaluate the performance of models in tasks like language modeling. It can provide a more interpretable way to understand the uncertainty of a model in predicting the next token in a\n",
    "sequence.\n",
    "\n",
    "Perplexity measures how well the probability distribution predicted by the model\n",
    "matches the actual distribution of the words in the dataset. Similar to the loss, a lower\n",
    "perplexity indicates that the model predictions are closer to the actual distribution.\n",
    "\n",
    "perplexity = torch.exp(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity is often considered more interpretable than the raw loss value because it signifies the effective vocabulary size about which the model is uncertain at each step. In the given example, this would translate to the model being unsure about which among 48,725 tokens in the vocabulary to generate as the next token.\n",
    "\n",
    "While cross-entropy represents the average negative log probability of correct predictions, perplexity translates this into the effective number of choices the model is uncertain about at each step. If a model assigns equal probability to all tokens in a vocabulary of size 𝑉, its perplexity is 𝑉, meaning it is as uncertain as random guessing. Lower perplexity indicates greater confidence, while higher perplexity suggests the model is struggling to distinguish between many possible outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the training and validations losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
     ]
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "    print(text_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt) # tokenizes the entire text\n",
    "        \n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            # use sliding window to chunk the book into overlapping sequences of max_length\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids) # returns total rows in the dataset\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx] # return single row\n",
    "        \n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    \n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\") # initialize the tokenizer\n",
    "\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride) # create the dataset\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, # create the dataloader\n",
    "                            drop_last=drop_last, num_workers=num_workers)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2, # ridiculously small batch size for demonstration purposes\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1265f1410>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a function to calculate loss entropy for a given batch\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1),\n",
    "        target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader) # iterate over all batches if num_batches is not specified\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader)) # reduces the number of batches if num batches exceeds the total number of batches\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item() # sum loss for each batch\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches # return the average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Training loss: 10.987583690219456\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "model.to(device)\n",
    "with torch.no_grad(): # disable gradient tracking for efficiency since we're not training\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Training\n",
    "\n",
    "1) Iterate over training epochs\n",
    "2) Iterate over batches in each training epochs\n",
    "3) Reset loss gradients from previous batch iteration\n",
    "4) Calculate loss on current batch\n",
    "5) Backward pass to calculate loss gradient\n",
    "6) Update model weights using loss gradients\n",
    "7) Print training and validation set losses\n",
    "8) Generate sample text for visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function for pretraining LLM\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], [] # initialize lists to store losses and tokens seen\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs): # starts main training loop\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # reset loss gradients to zero from the previous iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # backpropagate to compute gradients\n",
    "            optimizer.step() # update model parameters\n",
    "            tokens_seen += input_batch.numel() # count the number of tokens seen\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0: # evaluate the model on the validation set. Optional step\n",
    "                train_loss, val_loss = evaluate_model( # not defined yet\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample( # not define yet\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() # dropouts are disabled during evaluation for reproducibility\n",
    "    with torch.no_grad(): # disable gradient tracking for efficiency since we're not training\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "# evaluate_model gives a numeric loss  while generate_and_print_sample gives \n",
    "# a sample text for better understanding of the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.600\n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.179\n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.134\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.238\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1) # AdamW optimizer\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "    epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clear sign of overfitting to see the validation loss diverge early from the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text generation strategies\n",
    "\n",
    "model.to(\"cpu\") # move model to CPU for faster generation\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gisburn, he knew just what the surest way of the plain oak panelling of the room.\n",
      "\n",
      "\"Oh, a balancing, I had it over the mantel-piece, and he wouldn't let it stay.\"\n",
      "\n",
      "Yes--\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model, \n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens = 100,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model will always generate the same outputs even if we run the same input text, we would add the temperature parameter, which is a technique that adds a probabilist selection process to the next-token generation task -- replacing the previous greedy decoding from argmax -> function that samples from a probab distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'closer',\n",
       " 1: 'every',\n",
       " 2: 'effort',\n",
       " 3: 'forward',\n",
       " 4: 'inches',\n",
       " 5: 'moves',\n",
       " 6: 'pizza',\n",
       " 7: 'toward',\n",
       " 8: 'you'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {\n",
    "\"closer\": 0,\n",
    "\"every\": 1,\n",
    "\"effort\": 2,\n",
    "\"forward\": 3,\n",
    "\"inches\": 4,\n",
    "\"moves\": 5,\n",
    "\"pizza\": 6,\n",
    "\"toward\": 7,\n",
    "\"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "# a sample output logist from \"Every effort moves you\"\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closer: 73\n",
      "every: 0\n",
      "effort: 0\n",
      "forward: 582\n",
      "inches: 2\n",
      "moves: 0\n",
      "pizza: 0\n",
      "toward: 343\n"
     ]
    }
   ],
   "source": [
    "# but if we test it 1000 times:\n",
    "\n",
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
    "            for i in range(1000)]  # sample 1000 tokens\n",
    "    sample_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, count in enumerate(sample_ids):\n",
    "        print(f\"{inverse_vocab[i]}: {count.item()}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
    "        for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "    bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.38905610e+00 5.45981500e+01 4.03428793e+02 2.98095799e+03\n",
      " 2.20264658e+04]\n",
      "Temperature = 0.5: [2.90075868e-04 2.14338686e-03 1.58376057e-02 1.17024957e-01\n",
      " 8.64703974e-01]\n",
      "[  2.71828183   7.3890561   20.08553692  54.59815003 148.4131591 ]\n",
      "Temperature = 1.0: [0.01165623 0.03168492 0.08612854 0.23412166 0.63640865]\n",
      "[ 1.64872127  2.71828183  4.48168907  7.3890561  12.18249396]\n",
      "Temperature = 2.0: [0.05801222 0.09564598 0.15769356 0.25999272 0.42865553]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(logits, temperature=1.0):\n",
    "    # Scale the logits by dividing by the temperature\n",
    "    scaled_logits = logits / temperature\n",
    "    # Subtract the maximum value for numerical stability\n",
    "    exp_logits = np.exp(scaled_logits)\n",
    "    return exp_logits, exp_logits / np.sum(exp_logits)\n",
    "\n",
    "# Example logits\n",
    "logits = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Define different temperature values\n",
    "temperatures = [0.5, 1.0, 2.0]\n",
    "\n",
    "for T in temperatures:\n",
    "    exp_logits, probabilities = softmax(logits, temperature=T)\n",
    "    print(exp_logits)\n",
    "    print(f\"Temperature = {T}: {probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 1\n",
      "closer: 73\n",
      "every: 0\n",
      "effort: 0\n",
      "forward: 582\n",
      "inches: 2\n",
      "moves: 0\n",
      "pizza: 0\n",
      "toward: 343\n",
      "you: 0\n",
      "----------------------------------------\n",
      "Temperature: 0.1\n",
      "closer: 0\n",
      "every: 0\n",
      "effort: 0\n",
      "forward: 985\n",
      "inches: 0\n",
      "moves: 0\n",
      "pizza: 0\n",
      "toward: 15\n",
      "you: 0\n",
      "----------------------------------------\n",
      "Temperature: 5\n",
      "closer: 165\n",
      "every: 75\n",
      "effort: 42\n",
      "forward: 239\n",
      "inches: 71\n",
      "moves: 46\n",
      "pizza: 32\n",
      "toward: 227\n",
      "you: 103\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of temperatures to test\n",
    "temperatures = [1, 0.1, 5]\n",
    "\n",
    "# Define a function to sample 1000 tokens and print their frequencies\n",
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(1000)]\n",
    "    sample_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, count in enumerate(sample_ids):\n",
    "        print(f\"{inverse_vocab[i]}: {count.item()}\")\n",
    "\n",
    "# List of temperature values to test\n",
    "temperatures = [1, 0.1, 5]\n",
    "\n",
    "# Apply the softmax_with_temperature function and sample tokens for each temperature\n",
    "for T in temperatures:\n",
    "    print(f\"Temperature: {T}\")\n",
    "    probas = softmax_with_temperature(next_token_logits, T)\n",
    "    print_sampled_tokens(probas)\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lit-llm-usCjbgK0-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
